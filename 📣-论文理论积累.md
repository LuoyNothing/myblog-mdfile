---
title: 📣-论文理论积累
date: 2023-09-14 21:06:05
tags: 论文理论
categories: 论文实验
---



{% raw %}

# 📚  模型训练

1.为了防止过拟合，我们有一下两种方式。

1. 减少特征数：这个方法的坏处显而易见，直接去除了一部分特征，导致这一部分特征带来的影响直接消失。
2. 正则化：这就是接下来要讲的部分

2.正则化

- 我们需要一个方法，来抑制变量的影响，但是又不是直接让系数为0（去除变量）。那么我们只需要在**损失函数**的最后加上一项$$ {\textstyle \sum_{i=0}^{n}} \theta _i ^2$$即可。这里不一定要是平方，可以是一范数（绝对值），也可以是二范数（平方和）。加入这一个惩罚项之后，就能让指数更大的项系数更小，随着阶数的增加，系数处于一个急速增长的状态。那么我们加入这个惩罚项之后，指数越高的地方，系数如果越大就会导致损失变大，因此达到控制高阶系数的效果。

  $$\text { loss }=\sum_{i=1}^{n}\left(h_{\theta}(x)-y\right)^{2}+\lambda \sum_{j=1}^{n} \theta_{j}^{2}$$

- Pytorch中正则化的实现：

  ```python
  optimizer = optim.SGD(model.parameters(), lr=self.params.lr, weight_decay=self.params.decay, momentum=self.params.momentum)
  ```

随机梯度下降优化器里的weight_decay就是正则化的$$ \lambda$$，默认为0，不进行正则化处理。

# 📚  同态加密

## 🌸 相关问题

<font color=red>**1.通过同态加密技术加密的两个数据能够进行大小（>、<、=）比较吗？**</font>

答：不能直接进行对比大小，需要使用安全函数评估、协议等方法。

<font color=red>**2.同态加密中，由客户端还是服务器端生成密钥对，还是第三方生成？**</font>

答：由**客户端**生成，因为同态加密的本质是“可用不可见”，客户端拥有重要数据，但没有计算资源，只能委托第三方提供计算服务。数据经客户端生成的公钥加密后发送给服务器端进行计算。（在有些特定的应用中，可能会涉及到使用第三方机构来生成和管理密钥对，以提供额外的安全保障或信任。这种情况下，第三方机构可能会负责生成密钥对并向客户端和服务器分发相应的密钥材料）。但一般的，你有数据，你肯定不相信别人，所以密钥对由自己生成最放心。

总结：参与方和服务器都有自己的密钥对（公钥和私钥），一般由自己生成。

<font color=red>**3.密钥对在每个参与方都是一样的吗？如果一样的话，如果有参与方是恶意的？岂不是很危险？如果是不一样的，那不一样的密钥加密的数据可以加法运算吗？**</font>

答：密钥对通常是不同的，每个参与方都会有自己的密钥对，因为每个参与方需要进行不同的操作和计算，并且保持自己对密钥对的控制。数据是用公钥进行加密，如果数据方想给服务器传递什么重要数据的话，是拿着服务器放的公钥加密的。

<font color=red>**4.参与方用自己的公钥进行加密，收到密文后用私钥进行解密，（不同公钥加密的数据不能进行计算）这个过程中不同公钥加密的密文在服务器端怎么进行聚合呢？而且服务器端的公钥和私钥有什么作用呢？**</font>

答：在联邦学习中，每个参与方和服务器都有自己的密钥对，这种设置主要用于数据隐私和安全性的考虑。

当参与方在训练过程中生成上传更新时，他们使用自己的私钥来对更新进行数字签名，以确保更新的完整性和来源的可验证性。

然后，参与方使用服务端的公钥对加密后的更新进行加密，以确保数据的隐私性。这样，只有持有服务器私钥的服务端可以解密更新。在上传到服务器之后，服务端使用自己的私钥来对接收到的更新进行解密。解密后的更新可以被服务端聚合，以生成全局模型的更新。聚合过程可以采用各种算法，例如简单的加权平均或更复杂的模型聚合方法，以结合不同参与方的更新。





# 📚 差分隐私

## 🌸 这里给出cdp的推理过程

​	首先给出中心化差分隐私（CDP）的**严格定义**

​	$$\operatorname{Pr}[\mathcal{A}(D) \in S] \leqslant \operatorname{Pr}\left[\mathcal{A}\left(D^{\prime}\right) \in S\right] \times \mathrm{e}^{\epsilon}$$

​	定义（**松弛DP**） $$(\epsilon, \delta)$$-差分隐私  对于只有一个记录不同的两个数据集$$D$$和$$D'$$，一个随机算法$$M$$，以及对于任意的输出$$S\subset\text{Range}(M)$$，我们称随机算法$$M$$提供$$(\epsilon, \delta)$$-差分隐私保护，当且仅当其满足：

​	$$\operatorname{Pr}[\mathcal{M}(D) \in S] \leqslant \operatorname{Pr}\left[\mathcal{M}\left(D^{\prime}\right) \in S\right] \times \mathrm{e}^{\epsilon}+\delta$$

​	其中，$$\epsilon$$表示隐私预算，$$\delta$$表示失败概率。当$$\delta=0$$时，便得到了性能更好的$$\epsilon$$-差分隐私。$$\epsilon$$用于控制算法$$M$$在邻近数据集上获得相同输出的概率比值。$$\epsilon$$越小，那么算法在邻近数据集上获得相同输出的概率就越大，用户就通过输出结果无法判断数据到底是来自哪个数据集，从而达到隐私保护的目的。特别的，当$$\epsilon=0$$时，算法$$M$$在邻近数据集上得到相同的输出的概率是一样的。反之，$$\epsilon$$越大，其隐私保护的程度就越低。



**加拉普拉斯噪声的推导过程如下：**

$$\operatorname{Pr}[\mathcal{A}(D) = t] \leqslant \operatorname{Pr}\left[\mathcal{A}\left(D^{\prime}\right) =t\right] \times \mathrm{e}^{\epsilon}$$

这里的$A$是一个算法，我们希望通过$A$这个算法使得$\frac{\operatorname{Pr}[\mathcal{A}(D) = t]}{\operatorname{Pr}[\mathcal{A}(D^{\prime}) = t]}\le {e}^{\epsilon} $ 两个概率的比值小于等于${e}^{\epsilon}$，$$A$$是一个函数，我们想设计这个函数满足上面的条件，其中$$A(x) = F(x) + x$$，其中$$F(X)$$是原函数，我们通过在原函数上加一个噪声$$x$$（加一个分布）来设计这个$A$算法，根据所加噪声的量来使其达到上述条件。

那么怎么加？加多少呢？

我们先来看拉普拉斯噪声

$\frac{\operatorname{Pr}[\mathcal{A}(D) = t]}{\operatorname{Pr}[\mathcal{A}(D^{\prime}) = t]} = \frac{\operatorname{Pr}[\mathcal F(D) + x = t]}{\operatorname{Pr}[\mathcal F(D^{\prime}) + x= t]} = \frac{\operatorname{Pr}[\mathcal x = t - \mathcal F(D)]}{\operatorname{Pr}[\mathcal x= t - \mathcal F(D^{\prime})]} $

​	我们这里想用拉普拉斯加噪，也就是将$x$当做拉普拉斯分布，那么满足$\mathrm{e}^{\epsilon}$的条件下应该加多少噪声呢？，其中拉普拉斯分布的密度函数为$f(x \mid \mu, \beta )=\frac{1}{2 \beta} e^{-\frac{|x-\mu|}{\beta}}$，其中$\mu$是位置参数，$\beta$是尺度参数，这里令$\mu=0$，则$f(x \mid 0, \beta )=\frac{1}{2 \beta} e^{-\frac{|x|}{\beta}}$（也就是这里$\beta$应该怎么取值），将这个式子带进去可得：其中涉及三角不等式$\left | a \right | - \left | b \right | \le \left | a - b \right |$，即可得如下的计算过程。

$\frac{\frac{1}{2 \beta} e^{-\frac{|t - \mathcal F(D)|}{\beta}}}{ \frac{1}{2 \beta} e^{-\frac{|t - \mathcal F(D^{\prime})|}{\beta}}} = e^{\frac{|t - \mathcal F(D^{\prime}))| - |t - \mathcal F(D)|}{\beta}}  \le e^{\frac{|\mathcal F(D) - \mathcal F(D^{\prime})|}{\beta}} $

又因为敏感度的定义：$|\mathcal F(D) - \mathcal F(D^{\prime})| \le  \Delta f$

所以上述式子继续化简为：$\le e^{\frac{\Delta f}{\beta } } $

使用拉普拉斯噪声进行处理得到的概率比值$\le e^{\frac{\Delta f}{\beta } } $得满足定义条件，所以$\le e^{\frac{\Delta f}{\beta } } \le e^{\epsilon}$，即$\frac{\Delta f}{\beta } \le \epsilon$即可，最后$\beta$只要$\ge \frac{\Delta f}{\epsilon }$即可满足隐私保护条件。$\epsilon$ 我们称为隐私损失，隐私损失越小，分布相似度越高，隐私保护越高，$\beta$也就越大，图越平缓（如下图可见），所加噪声越多。

<p align=center><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/ad919ed16ab34ca1b92d4d61cde7a2fb~tplv-k3u1fbpfcp-jj-mark:0:0:0:0:q75.image#?w=372&h=264&s=14908&e=png&a=1&b=ffffff" alt="image.png"  width="40%"/></p>

**下面开始推导加高斯噪声的过程：**

松弛差分隐私定义：

$$\operatorname{Pr}[\mathcal{A}(D) = t] \leqslant \operatorname{Pr}\left[\mathcal{A}\left(D^{\prime}\right) =t\right] \times \mathrm{e}^{\epsilon}+\delta$$

上述表示违反严格差分隐私的概率为$$\delta$$，也可以这么写$\operatorname{Pr}\left[\frac{\operatorname{Pr}[\mathcal{A}(D) = t]}{\operatorname{Pr}[\mathcal{A}(D^{\prime}) = t]}\ge {e}^{\epsilon}\right] \le \delta $

这里我们要加高斯分布，我们还是先来计算概率的比值：


$\frac{\operatorname{Pr}[\mathcal{A}(D) = t]}{\operatorname{Pr}[\mathcal{A}(D^{\prime}) = t]} = \frac{\operatorname{Pr}[\mathcal F(D) + x = t]}{\operatorname{Pr}[\mathcal F(D^{\prime}) + x= t]} = \frac{\operatorname{Pr}[\mathcal x = t - \mathcal F(D)]}{\operatorname{Pr}[\mathcal x= t - \mathcal F(D^{\prime})]} $

这里$x$就表示我们要加的高斯噪声，高斯密度函数为$f(x \mid \mu, \sigma )=\frac{1}{\sqrt{2 \pi} \sigma} e^{-\frac{(x-\mu)^{2}}{2 \sigma^{2}}}$，其中$\mu$称为均值，$\sigma^2$称为方差，$\sigma$表示标准差。这里均值先取0，即为$f(x \mid 0, \sigma )=\frac{1}{\sqrt{2 \pi} \sigma} e^{-\frac{x^{2}}{2 \sigma^{2}}}$。

这里就不能像上面一样把密度函数带进去，因为$x^2$是消不掉的，所以这里，我们让$t - \mathcal F(D) = x$，然后$t - \mathcal F(D^{\prime})) = x + \Delta f$，这里的$\Delta f$是敏感度，先暂时考虑=的情况，然后带入进去看一下：

$\frac{\frac{1}{\sqrt{2 \pi} \sigma} e^{-\frac{{(t - \mathcal F(D))}^{2}}{2 \sigma^{2}}}}{\frac{1}{\sqrt{2 \pi} \sigma} e^{-\frac{(t - \mathcal F(D^{\prime}))^{2}}{2 \sigma^{2}}}} = e^{\frac{(t - \mathcal F(D^{\prime}))^{2} - (t - \mathcal F(D))^{2}}{2 \sigma^{2}}} = e^{\frac{(x + \Delta f)^{2} - x^{2}}{2 \sigma^{2}}} = e^{\frac{2x \Delta f + {\Delta f}^2}{2 \sigma^{2}}}$

最右边得到的式子还是一个高斯分布，也可以称为亚高斯分布。我们要想满足差分隐私的条件，就需要使得

$\frac{2x \Delta f + {\Delta f}^2}{2 \sigma^{2}} \le \epsilon$，把$x$全部放到左边去，可以得到：$x \le \frac{\sigma ^2 \epsilon }{\Delta f} - \frac{\Delta f}{2} $，这个$x$本身是取任意值的，是不能让他小于某个值，所以不能满足严格差分隐私，这里呢我们让$1- \delta$的概率满足$\le \epsilon$即可，也就是让$\delta$的概率满足$\ge \epsilon$即可，即：

$$\operatorname{Pr}[|x| \ge \frac{\sigma ^2 \epsilon }{\Delta f} - \frac{\Delta f}{2}] \leqslant \delta$$，也就是说这个x违反严格差分隐私的概率控制在$\delta$范围内，图像具有对称性，看一边的话则为：$$\operatorname{Pr}[x \ge \frac{\sigma ^2 \epsilon }{\Delta f} - \frac{\Delta f}{2}] \leqslant \frac {\delta}{2}$$





我要给全局模型参数加高斯噪声，其中$$L\sim \operatorname{Gaussian}\left(0,\sigma^2 \right)$$为添加的随机噪声概率密度函数，即服从参数$$\mu=0,  $$$$\sigma=\sqrt{2 \operatorname{In} \frac{1.25}{\delta}} \times \frac{\Delta f}{\epsilon}$$的高斯分布。

我想知道其中的$\Delta f$、$\epsilon$、$\delta$ 如何设置？敏感度如何计算得出的？



# 📚 模型的优缺点

**🌸 模型的优点**



**🌸 模型的缺点**

由于加了同态加密来保护隐私，因此性能不太好。

{% endraw %}
