---
title: 📣 分析实验过程
date: 2023-09-04 17:50:28
tags: ['backdoors101', '持续更新中']
categories: 论文实验
---

# 1.联邦学习过程

从main出发——> fl_run（联邦学习总的训练过程）——> run_fl_round（联邦学习的一轮训练）——>test（每轮进行测试--测试正常样本和后门样本）——>save_model（保存模型）

# 2.联邦学习一轮训练

## 1.helper里能干的事情

1. 初始化任务
   - 给params赋值
   - `make_task` 找到运行联邦任务的py文件
   - `make_synthesizer`找到后门攻击对应的py文件，并初始化攻击
   - **1.初始化全局模型resnet18**
   
   在联邦学习中初始化 ResNet-18 模型的过程与常规深度学习中的初始化过程类似。初始化 ResNet-18 模型的方法通常是**随机初始化**，以确保模型在各个参与方的本地训练中具有足够的随机性，以便更好地学习各自的数据。实现如下：
   
   ```python
   # 初始化 ResNet-18 模型 
   resnet18 = models.resnet18(pretrained=False)  # 随机初始化
   # 这些参数会根据某个分布（如均匀分布或正态分布）中的随机值进行初始化
   ```
   
2. 保存模型

3. 保存断点

## 2.`run_fl_round`中干的事情

1. 加载全局模型和局部模型
2. 随机选择参与者（可能包括恶意参与者）：fl_task文件中
3. 创建一个新的权重累积字典
4. 接着每个参与者在本地训练全局模型，得到上传更新
5. 然后更新全局模型

## 3.全局模型参数和本地模型参数

1.初始化全局模型参数



2.全局模型参数



3.本地模型参数



# 3.对参与者进行中毒和随机选择参与者

## 1.随机选择10个客户端

**实现**：`fl_task`文件中`sample_users_for_round`

里面的实现思路：

1. 在100个参与者中随机选择10个参与者，是从100个id中选择10个id
2. 新建一个参与者样本列表
3. 对于这10个用户，来查看其是否是恶意的，并对每个用户打标记（恶意和非恶意）
4. 将打了标记的10个参与者加入参与者样本列表

## 2.给参与者打标记

**实现**：`fl_task`文件中`check_user_compromised`

里面的实现思路：

1. 先让参与者为正常参与者
2. 根据单轮攻击还是多轮攻击中的攻击者列表来给当前参与者打标记
3. 返回标记

# 4.参与者本地的训练过程

**实现**：`training`文件里

实现思路如下：

1. 将全局模型复制到本地模型中，实现：`fl_task`文件中`copy_params`
2. 选择优化器SGD-随机梯度下降算法，用于优化损失函数，实现：`task`文件中的`make_optimizer`
3. 开始本地轮次的训练：
   1. 如果是恶意参与者，就怎么训练
   2. 如果是正常参与者，就怎么训练
4. 计算本地更新，
   1. 正常参与者，实现：`fl_task`文件中`get_fl_update`。思路：本地模型—上轮全局模型
   2. 恶意参与者，在正常参与者计算过程上还会乘上一个数（fl_weight_scale），**从而增大该更新的权重**。实现：`attack`文件中的`fl_scale_update`。
5. 可以给上传更新用同态加密技术进行加密，实现：`fl_task`文件中`get_fl_update`
5. 积累权重然后记录到权重累积字典，实现：`fl_task`文件中`accumulate_weights`
6. 更新全局模型，实现：`fl_task`文件中`update_global_model`

# 5.本地模型训练的过程

**实现**：training.py文件中

实现的思路如下：

1. 确定损失函数：交叉熵，实现：`task`文件中的`make_criterion`
2. 开启训练模式
3. 开始本地轮次的批次训练：
   1. 获得当前的batch，把数据加载到设备上
   2. 梯度为0
   3. 计算损失，实现：`attack.py`中的`compute_blind_loss`
   4. 将损失loss 向输入侧进行反向传播
   5. SGD优化器对值进行更新
   6. 打印训练时期的精度和损失等info信息，实现：`helper.py`中的`report_training_losses_scales`

# 6.本地模型计算损失的过程

**实现**：`attack.py`中的`compute_blind_loss`

实现的思路如下：

1. 记录训练的任务是什么，是后门任务和正常任务
2. 获得后门训练批次，这里是加后门攻击的过程，实现：`synthesizer`中`make_backdoor_batch`
3. 利用多梯度下降算法来计算损失和梯度，实现：`losses.loss_functions`中的`compute_all_losses_and_grads`

## 1.多梯度下降算法MGDA

**前置知识：**

多梯度下降算法（Multi-Gradient Descent Algorithm，简称MGDA）是一种优化算法，旨在解决多目标优化问题，也就是在一个优化问题中存在多个目标函数需要最小化或最大化的情况。MGDA 的思路是通过协调多个目标函数的优化过程，以在不同目标之间取得平衡。

下面是 MGDA 算法的基本思路：

1. **多目标问题设定：** 首先，确定一个多目标优化问题，其中有多个待优化的目标函数。这里是正常任务和后门任务
2. **权衡策略：** 在 MGDA 中，需要定义一个**权衡策略**，该策略决定了如何将多个目标函数结合起来形成一个综合目标，以便进行单一的优化。这个权衡策略通常包括权重或权衡参数，用于调整不同目标函数的相对重要性。这里的权衡策略是什么？
3. **梯度计算：** 对于每个目标函数，计算其相对于优化变量的梯度。这意味着对每个目标函数进行单独的梯度计算。
4. **合并梯度：** 使用权衡策略将不同目标函数的梯度合并为一个综合梯度。这通常涉及将不同目标函数的梯度按照其权重进行加权求和。
5. **参数更新：** 使用合并的综合梯度来更新优化变量，通常使用标准的梯度下降或其他优化方法来实现。
6. **迭代优化：** 重复步骤 3 到步骤 5，直到满足停止条件（例如达到最大迭代次数或梯度阈值）。
7. **结果分析：** 最终的优化结果是一个在多个目标函数下达到权衡的解决方案。

MGDA 的主要挑战在于权衡策略的选择，因为不同的权衡策略可能会导致不同的最终解决方案。因此，需要根据具体问题的性质和需求来选择适当的权衡策略。

总的来说，MGDA 旨在处理多目标优化问题，通过协调不同目标函数的优化过程，寻找一个在多个目标之间取得平衡的解决方案。它在多领域的优化问题中都有应用，包括机器学习、控制系统、工程优化等领域。



以下是一个简单的例子，说明如何使用MGDA来解决一个多目标优化问题：

假设你是一家制造公司的经理，你需要决定生产两种不同的产品A和B。你有两个关键的目标：最大化产品A的利润和最大化产品B的销售量。然而，这两个目标之间存在权衡，因为提高产品A的利润可能会导致产品B的销售量下降，反之亦然。

问题设定如下：

- 目标1：最大化产品A的利润（表示为Profit_A）
- 目标2：最大化产品B的销售量（表示为Sales_B）

你可以使用MGDA来解决这个问题的优化过程：

1. 定义权衡策略：你需要定义一个权衡策略来决定在优化过程中分配多少资源（生产能力、广告预算等）给产品A和产品B。例如，你可以分配权重alpha给产品A的利润，权重(1-alpha)给产品B的销售量，其中alpha是一个介于0和1之间的参数，表示你对产品A和产品B的相对重要性。
2. 梯度计算：针对每个目标函数，计算其相对于资源分配（例如生产量、广告投入等）的梯度。这将涉及计算Profit_A和Sales_B关于资源分配的梯度。
3. 合并梯度：使用权衡策略中的权重alpha和(1-alpha)将两个目标函数的梯度加权合并为一个综合梯度。
4. 参数更新：使用合并的综合梯度来更新资源分配的变量。这可能涉及使用标准的梯度下降或其他优化算法来更新资源分配。
5. 迭代优化：重复步骤3和步骤4，直到达到停止条件，例如达到最大迭代次数或梯度变化很小。
6. 结果分析：最终的优化结果是一组资源分配，这些资源分配在产品A的利润和产品B的销售量之间取得了权衡。

通过调整权衡策略中的参数alpha，你可以探索不同的权衡点，以找到最适合公司目标的资源分配策略。这个例子说明了如何使用MGDA来处理多目标优化问题，并在不同目标之间进行权衡，以找到最佳解决方案。



**实现**：`losses.loss_functions`中的`compute_all_losses_and_grads`

**实现思路如下：**

1. 新建一个损失和梯度空字典
2. 对任务进行分类：
   1. 正常任务，实现：`losses.loss_functions`中的`compute_normal_loss`
   2. 后门任务，实现：`losses.loss_functions`中的`compute_backdoor_loss`



对于正常任务计算损失和梯度，思路如下：

1. 得到模型的输出
2. 利用交叉熵计算损失
3. 



# 7.权重积累过程



# 8.更新全局模型过程



# 9.超参数设置

- 本地学习率：$\eta=0.01$
- 联邦学习的学习率：$\eta_{fl}=10$



# 10.自己论文的符号表示

**本地符号：**

- 参与者i：$c_i$
- 

FL整个过程中的符号：

- 参与者集合：$C={c_1,c_2,...,c_n}$



# 11.查看模型相关信息（√）

这里先搭建一个简单的网络：一共有3层，第一层又包括2个全连接层，第三次也包括2个全连接层。

<p align=center><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/91f9f1a58d134209b4e38f871a4aaa02~tplv-k3u1fbpfcp-jj-mark:0:0:0:0:q75.image#?w=407&h=505&s=160726&e=png&b=1d1e23" alt="image.png"  width="30%"/></p>

```python
print(global_model) 			# ①直接打印整个模型

for layer in global_model.modules():		# 循环读取每一层
    print(type(layer))						# ② 每一层的类型
    print(layer)							# ③ 

for name, layer in global_model.named_modules():	# 循环读取每一层，在上一层的基础上，把名字也打印出来
    print(name, type(layer))				# ④ 每一层的名字和类型
    print(name, layer)						

for name, layer in global_model.named_children()：# 遍历第一层，不会递归子网络
	print(name, layer)						# ⑤

for name, param in global_model.named_parameters()：# 打印每一层的名字和参数
	print(name, param.shape)						# ⑥

for name, param in global_model.state_dict().item()：# 将模型中参数键值以字典的方式迭代处理
	print(name, layer.shape)								# ⑦
```



代码①的结果为：

<p align=center><img src="https://p9-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/c0feca889cb6474ba9c2cf579b1ee953~tplv-k3u1fbpfcp-jj-mark:0:0:0:0:q75.image#?w=537&h=293&s=89757&e=png&b=1d1e23" alt="image.png"  width="50%"/></p>

代码②的结果为：

<p align=center><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/d4a83c0757da4dcda0ebdbb7623512c6~tplv-k3u1fbpfcp-jj-mark:0:0:0:0:q75.image#?w=495&h=211&s=80530&e=png&b=1d1e23" alt="image.png"  width="50%"/></p>

代码③的结果：先打印整个，再打印每一层。递归出了每一层

<p align=center><img src="https://p9-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/5ba6e90050ef4d3c83602ca5d19bb2f7~tplv-k3u1fbpfcp-jj-mark:0:0:0:0:q75.image#?w=598&h=633&s=279245&e=png&b=1d1e23" alt="image.png" width="50%" /></p>

代码④的结果：

<p align=center><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/7d7aea08535e46cf9e0ab973aa5d9a9c~tplv-k3u1fbpfcp-jj-mark:0:0:0:0:q75.image#?w=525&h=213&s=93798&e=png&b=1d1e23" alt="image.png" width="50%" /></p>

代码⑤的结果：

<p align=center><img src="https://p1-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/b1042830e9524ae3b46ee1d8bccc299d~tplv-k3u1fbpfcp-jj-mark:0:0:0:0:q75.image#?w=522&h=241&s=85377&e=png&b=1d1e23" alt="image.png" width="50%" /></p>

代码⑥的结果：

<p align=center><img src="https://p1-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/9fcd4f3cf530466286ae7bd7438aa6bf~tplv-k3u1fbpfcp-jj-mark:0:0:0:0:q75.image#?w=344&h=265&s=84625&e=png&b=1d1e23" alt="image.png"  width="40%"/></p>

代码⑦的结果：

<p align=center><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/61f7d6994acb405b857a65f50587b1f3~tplv-k3u1fbpfcp-jj-mark:0:0:0:0:q75.image#?w=367&h=271&s=79401&e=png&b=1d1e23" alt="image.png" width="40%" /></p>



# 12.同态加密

实现：`fl_task`文件中`get_fl_update`

查看生成的Paillier加密的公钥的具体数值：可以访问公钥对象的属性。在phe库中，公钥对象通常具有属性`n`，它代表了公钥的模数（modulus）。通过访问`public_key.n`，您可以获取生成的公钥的模数值，这是Paillier加密中的关键参数之一。这个值通常用于加密数据。请注意，这只是公钥的一部分，其他参数通常也存储在公钥对象中，但模数通常是最重要的部分。



## 🌸 相关问题

**1.通过同态加密技术加密的两个数据能够进行大小（>、<、=）比较吗？**

答：不能直接进行对比大小，需要使用安全函数评估、协议等方法。

**2.同态加密中，由客户端还是服务器端生成密钥对，还是第三方生成？**

答：由客户端生成，因为同态加密的本质是“可用不可见”，客户端拥有重要数据，但没有计算资源，只能委托第三方提供计算服务。数据经客户端生成的公钥加密后发送给服务器端进行计算。（在有些特定的应用中，可能会涉及到使用第三方机构来生成和管理密钥对，以提供额外的安全保障或信任。这种情况下，第三方机构可能会负责生成密钥对并向客户端和服务器分发相应的密钥材料）。但一般的，你有数据，你肯定不相信别人，所以密钥对由自己生成最放心。

总结：参与方和服务器都有自己的密钥对（公钥和私钥），一般由自己生成。

**3.密钥对在每个参与方都是一样的吗？如果一样的话，如果有参与方是恶意的？岂不是很危险？如果是不一样的，那不一样的密钥加密的数据可以加法运算吗？**

答：密钥对通常是不同的，每个参与方都会有自己的密钥对，因为每个参与方需要进行不同的操作和计算，并且保持自己对密钥对的控制。数据是用公钥进行加密，如果数据方想给服务器发传递什么重要数据的话，是拿着服务器放的公钥加密的。

**4.参与方用自己的公钥进行加密，收到密文后用私钥进行解密，（不同公钥加密的数据不能进行计算）这个过程中不同公钥加密的密文在服务器端怎么进行聚合呢？而且服务器端的公钥和私钥有什么作用呢？**



# 13.实验中的小技巧

1.让代码在某一行停止，在那一行后面加`sys.exit(1)`。



# 文末
