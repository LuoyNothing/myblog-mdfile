---
title: 📣 攻击实验
date: 2023-09-04 17:50:28
tags: ['攻击实验', '持续更新中']
categories: 论文实验
---



我想做哪些攻击呢？

白块、随机矩阵、高斯噪声、椒盐噪声、语义后门、模型替换后门

引入高频信号可能会改变图像的视觉外观

# 1.单次攻击

## 1.白块攻击（√）

修改参数：

```python
# 后门攻击的方式
synthesizer: Baikuai
# 通信轮次，在不同轮次注入后门则选择的总轮次不同，50轮设置150轮，100轮设置200轮，因为我主要是想看注入后门之后100轮的后门持久情况
epochs: 300
# 本地训练轮次
fl_local_epochs: 2
# 单次攻击
fl_single_epoch_attack: True
# 这是模型替换后门增加权重的，这里默认100，我改为1
fl_weight_scale: 1
# 攻击者数量
fl_number_of_adversaries: 10
# 单次攻击轮次
fl_single_epoch_attack: 200
# 恶意参与方的样本比例
poisoning_proportion: 0.5
```

取名：cifar10_resnet18_oneBaikuai_50_10：表示数据集-模型-单次pattern攻击-攻击轮次-攻击者数量

单次攻击的变量：1.攻击者数量；2.不同的攻击轮次。我这里先跑一下不同的攻击轮次，然后攻击之后100轮的情况，如下所示：

画图1：pattern攻击在不同的攻击轮次的后门持久性，包括（50---√    ,100,150,200）

## 2.pattern（随机矩阵）后门攻击（√）

修改参数：

```python
# 后门攻击的方式
synthesizer: Pattern
# 通信轮次
epochs: 150
# 本地训练轮次
fl_local_epochs: 2
# 单次攻击
fl_single_epoch_attack: True
# 这是模型替换后门增加权重的，这里默认100，我改为1
fl_weight_scale: 1
# 攻击者数量
fl_number_of_adversaries: 10
# 单次攻击轮次
fl_single_epoch_attack: 200
# 恶意参与方的样本比例
poisoning_proportion: 0.5
```

取名：cifar10_resnet18_onePattern_50_10：表示数据集-模型-单次pattern攻击-攻击轮次-攻击者数量



单次攻击的变量：1.攻击者数量；2.不同的攻击轮次。我这里先跑一下不同的攻击轮次，然后攻击之后100轮的情况，如下所示：

画图1：pattern攻击在不同的攻击轮次的后门持久性，包括（50---√,100,150,200）





## 3.高斯噪声

修改参数：

```python
# 后门攻击的方式
synthesizer: Noice
# 通信轮次
epochs: 300
# 本地训练轮次
fl_local_epochs: 2
# 单次攻击
fl_single_epoch_attack: True
# 这是模型替换后门增加权重的，这里默认100，我改为1
fl_weight_scale: 1
# 攻击者数量
fl_number_of_adversaries: 10
# 单次攻击轮次
fl_single_epoch_attack: 200
# 恶意参与方的样本比例
poisoning_proportion: 0.5
```

取名：cifar10_resnet18_oneNoise_50_10：表示数据集-模型-单次pattern攻击-攻击轮次-攻击者数量

单次攻击的变量：1.攻击者数量；2.不同的攻击轮次。我这里先跑一下不同的攻击轮次，然后攻击之后100轮的情况，如下所示：

画图1：pattern攻击在不同的攻击轮次的后门持久性，包括（50---√,100,150,200）





## 4.语义后门攻击

1.cifar10数据集

选择的特征图片：

暂缓，因为要打标记，挺累的，可以换别的后门攻击来操作。



## 5.模型替换后门（√）

服务器收到客户端的更新根据下面公式聚合得到一个全局模型：$$G^{t+1}=G^{t}+\frac{\eta}{n} \sum_{i=1}^{m}\Delta \boldsymbol{w}_{i}^{r+1}$$，

模型替换：$$X=G^{t}+\frac{\eta}{n} \sum_{i=1}^{m}\Delta \boldsymbol{w}_{i}^{r+1}$$

随着训练轮次增多，$$\Delta \boldsymbol{w}_{i}^{r+1}→0$$，所以最后提交的恶意更新（假设第k个客户端为恶意客户端）为：$$\Delta \boldsymbol{w}_{k}^{r+1}=\frac{n}{\eta} (X-G^{t})-\sum_{i=1,i≠k}^{m}\Delta \boldsymbol{w}_{i}^{r+1} \approx \frac{n}{\eta}\left(X-G^{t}\right)$$

**这种攻击将后门模型 X 的权重缩放为$$\gamma =\frac{\eta}{n}$$**，以确保后门在平均聚合算法中存活，全局模型能够被 X 替换



**这个攻击的实现很简单，就是提高恶意更新的权重。**（已实现）



# 2.多次攻击





# 遇到的问题：

1.联邦学习的更新范数差别太大了，以至于损失值为Nan，在fl_task的get_update_norm函数中打印的范数。







